{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xAjgpcCeZunT"
   },
   "source": [
    "Exercises\n",
    "========================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2     t\n",
       "0   0   0  1.00\n",
       "1   0   1  1.50\n",
       "2   1   0  1.75\n",
       "3   1   1  2.25"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame([[0,0,1],[0,1,1.5],[1,0,1.75],[1,1,2.25]],columns=['X1','X2','t'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X1  X2\n",
       "0   0   0\n",
       "1   0   1\n",
       "2   1   0\n",
       "3   1   1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data.iloc[:,:2]\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because this is a learning exercise, here are the answers we are going to hunt for using gradient descent. In other words, your last theta should be w and b given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 1.5 , 1.75, 2.25])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w = np.array([0.75,0.5])\n",
    "b = 1\n",
    "y = np.dot(X,w)+b\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our y functions are:\n",
    "\n",
    "$y_1 = 0*w_1+0*w_2+b$\n",
    "\n",
    "$y_2 = 0*w_1+1*w_2+b$\n",
    "\n",
    "$y_3 = 1*w_1+0*w_2+b$\n",
    "\n",
    "$y_4 = 1*w_1+1*w_2+b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our Loss functions are:\n",
    "\n",
    "$L_1 = (b - 1)^2$\n",
    "\n",
    "$L_2 = (1*w_2+b - 1.5)^2$\n",
    "\n",
    "$L_3 = (1*w_1+b - 1.75)^2$\n",
    "\n",
    "$L_4 = (1*w_1+1*w_2+b - 2.25)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our derivatives are:\n",
    "\n",
    "$\\frac{\\delta L_1}{\\delta w1} = 0$\n",
    "\n",
    "$\\frac{\\delta L_2}{\\delta w1} = 0$\n",
    "\n",
    "$\\frac{\\delta L_3}{\\delta w1} = 2(w_1+b-1.75)$\n",
    "\n",
    "$\\frac{\\delta L_4}{\\delta w1} = 2(w_1+w_2+b-2.25)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta L_1}{\\delta w2} = 0$\n",
    "\n",
    "$\\frac{\\delta L_2}{\\delta w2} = 2(w_2+b-1.5)$\n",
    "\n",
    "$\\frac{\\delta L_3}{\\delta w2} = 0$\n",
    "\n",
    "$\\frac{\\delta L_4}{\\delta w2} = 2(w_1+w_2+b-2.25)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\frac{\\delta L_1}{\\delta b} = 2(b-1)$\n",
    "\n",
    "$\\frac{\\delta L_2}{\\delta b} = 2(w_2+b-1.5)$\n",
    "\n",
    "$\\frac{\\delta L_3}{\\delta b} = 2(w_1+b-1.75)$\n",
    "\n",
    "$\\frac{\\delta L_4}{\\delta b} = 2(w_1+w_2+b-2.25)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first take on gradient descent will assume you can symbolically find the gradient of a function. So you can use the derivatives I supplied above:\n",
    "\n",
    "Gradient descent says:\n",
    "\n",
    "$w_1 = w_1 - \\alpha \\frac{1}{4} \\left(\\sum_{i=1}^4\\frac{dF_i}{dw_1}\\right)$\n",
    "\n",
    "$w_2 = w_2 - \\alpha \\frac{1}{4} \\left(\\sum_{i=1}^4\\frac{dF_i}{dw_2}\\right)$\n",
    "\n",
    "$b = b - \\alpha \\frac{1}{4} \\left(\\sum_{i=1}^4\\frac{dF_i}{db}\\right)$\n",
    "\n",
    "We will set $\\alpha=0.1$.\n",
    "\n",
    "We will now define the derivatives programmatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be all zeros: [0, 0, 0.0, 0.0]\n",
      "This should be non-zero: [0, 0, -1.9558606118191404, -2.249714168707155]\n",
      "This should be non-zero: [0, 0, 0.8630453724710057, 2.3127478270825508]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "gradients_w1 = [lambda w1,w2,b: 0, lambda w1,w2,b: 0, lambda w1,w2,b: 2*(w1+b-1.75), lambda w1,w2,b: 2*(w1+w2+b-2.25)]\n",
    "print('This should be all zeros:',[gradients_w1[i](0.75,0.5,1) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_w1[i](0.75-random.random(),0.5-random.random(),1-random.random()) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_w1[i](0.75+random.random(),0.5+random.random(),1+random.random()) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be all zeros: [0, 0.0, 0, 0.0]\n",
      "This should be non-zero: [0, -2.3241995491654555, 0, -3.126424457796624]\n",
      "This should be non-zero: [0, 1.1328788511111085, 0, 4.145188931717534]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "gradients_w2 = [lambda w1,w2,b: 0, lambda w1,w2,b: 2*(w2+b-1.5), lambda w1,w2,b: 0, lambda w1,w2,b: 2*(w1+w2+b-2.25)]\n",
    "print('This should be all zeros:',[gradients_w2[i](0.75,0.5,1) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_w2[i](0.75-random.random(),0.5-random.random(),1-random.random()) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_w2[i](0.75+random.random(),0.5+random.random(),1+random.random()) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be all zeros: [0, 0.0, 0.0, 0.0]\n",
      "This should be non-zero: [-0.3151550570048449, -0.703811464420725, -1.423329903539193, -1.5042867464551835]\n",
      "This should be non-zero: [0.13225633255110392, 1.437089649153192, 2.5642209808008074, 0.9384509013889808]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "gradients_b = [lambda w1,w2,b: 2*(b-1), lambda w1,w2,b: 2*(w2+b-1.5), lambda w1,w2,b: 2*(w2+b-1.5), lambda w1,w2,b: 2*(w1+w2+b-2.25)]\n",
    "print('This should be all zeros:',[gradients_b[i](0.75,0.5,1) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_b[i](0.75-random.random(),0.5-random.random(),1-random.random()) for i in range(4)])\n",
    "print('This should be non-zero:',[gradients_b[i](0.75+random.random(),0.5+random.random(),1+random.random()) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       [0.5, -0.2, 2.5]\n",
       "1                 [0.41000000000000003, -0.2675, 2.3175]\n",
       "2                          [0.350625, -0.3055, 2.186125]\n",
       "3                    [0.312225, -0.32359375, 2.08969375]\n",
       "4      [0.28821281249999997, -0.328315, 2.01718281249...\n",
       "                             ...                        \n",
       "496    [0.7499998348770656, 0.49999983487304656, 1.00...\n",
       "497    [0.7499998400594908, 0.4999998400556728, 1.000...\n",
       "498    [0.7499998450792664, 0.4999998450756393, 1.000...\n",
       "499    [0.749999849941497, 0.4999998499380513, 1.0000...\n",
       "500    [0.7499998546511271, 0.4999998546478536, 1.000...\n",
       "Length: 501, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradient_descent\n",
    "thetas = gradient_descent.minimize_gradient_descent([gradients_w1,gradients_w2,gradients_b],0.1,[0.5,-0.2,2.5])\n",
    "pd.Series(thetas)\n",
    "# please note that I only add the pd.Series, so the output is nicely formatted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be all zeros, but is it...: [0, 0, 0.0, 0.0]\n",
      "This should be all zeros, but is it...: [0, 0.0, 0, 0.0]\n",
      "This should be all zeros, but is it...: [0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "print('This should be all zeros, but is it...:',[gradients_w1[i](0.75,0.5,1) for i in range(4)])\n",
    "print('This should be all zeros, but is it...:',[gradients_w2[i](0.75,0.5,1) for i in range(4)])\n",
    "print('This should be all zeros, but is it...:',[gradients_b[i](0.75,0.5,1) for i in range(4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000017, 1.50000003, 1.75000003, 2.24999988])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "w_predicted = np.array(thetas[-1][:2])\n",
    "b_predicted = thetas[-1][-1]\n",
    "y = np.dot(X,w_predicted)+b_predicted\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now what if you can't or don't want to find the derivatives symbolically? \n",
    "You can always estimate the gradient analytically using the difference quotient:\n",
    "\n",
    "$[L(\\theta+h)-L(\\theta)]/h$,\n",
    "\n",
    "where h is a scalar parameter. Let's give it a shot with our functions. As a reminder, they are:\n",
    "\n",
    "$L_1 = (b - 1)^2$\n",
    "\n",
    "$L_2 = (1*w_2+b - 1.5)^2$\n",
    "\n",
    "$L_3 = (1*w_1+b - 1.75)^2$\n",
    "\n",
    "$L_4 = (1*w_1+1*w_2+b - 2.25)^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F1_func = lambda w1,w2,b: (b-1)**2\n",
    "F1_func(w[0],w[1],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F2_func = lambda w1,w2,b: (w2+b-1.5)**2\n",
    "F2_func(w[0],w[1],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F3_func = lambda w1,w2,b: (w1+b-1.75)**2\n",
    "F3_func(w[0],w[1],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F4_func = lambda w1,w2,b: (w1+w2+b-2.25)**2\n",
    "F4_func(w[0],w[1],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_func = lambda w1,w2,b: 1/4*(F1_func(w1,w2,b)+F2_func(w1,w2,b)+F3_func(w1,w2,b)+F4_func(w1,w2,b))\n",
    "R_func(w[0],w[1],b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                       [0.5, -0.2, 2.5]\n",
       "1      [0.4095000000000022, -0.2680000000000014, 2.29...\n",
       "2      [0.3520500000000022, -0.3040750000000035, 2.14...\n",
       "3      [0.3170437500000002, -0.3187750000000043, 2.03...\n",
       "4      [0.29725387500000044, -0.31927393750000405, 1....\n",
       "                             ...                        \n",
       "496    [0.7499998915095999, 0.49999989150558083, 0.99...\n",
       "497    [0.749999894914635, 0.4999998949108169, 0.9950...\n",
       "498    [0.7499998982128018, 0.4999998982091746, 0.995...\n",
       "499    [0.7499999014074543, 0.49999990140400846, 0.99...\n",
       "500    [0.7499999045018414, 0.4999999044985678, 0.995...\n",
       "Length: 501, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = gradient_descent.minimize_gradient_descent_analytically(R_func,0.1,[0.5,-0.2,2.5],0.01)\n",
    "pd.Series(thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'R_func' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mR_func\u001b[49m(\u001b[38;5;241m*\u001b[39mthetas[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;66;03m# Shouldn't be too bad :)\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'R_func' is not defined"
     ]
    }
   ],
   "source": [
    "R_func(*thetas[-1]) # Shouldn't be too bad :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QsH0n-lhLnRI"
   },
   "outputs": [],
   "source": [
    "# Good job!\n",
    "# Woohoo!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5Ar9RvAkhCB"
   },
   "source": [
    "# Run Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LxBVRiFdkhCB",
    "outputId": "6ed719ad-3732-4e0c-9582-dc4a68e09940"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.10.7, pytest-8.3.3, pluggy-1.5.0\n",
      "rootdir: /Users/michael.murray.iv/Desktop/Fall 2024/487/stochastic_gradient_descent\n",
      "plugins: anyio-4.2.0\n",
      "collected 9 items\n",
      "\n",
      "test_Assignment4.py \u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m.\u001b[0m\u001b[32m                                            [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m9 passed\u001b[0m\u001b[32m in 0.68s\u001b[0m\u001b[32m ===============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pytest test_Assignment4.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4wGFMbwGkhCB"
   },
   "source": [
    "# Push code to repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QKOunr7ZkhCB",
    "outputId": "1ab36086-82ed-4aef-bab1-d269355c170d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 236c519] implemented adam. May need additional tests for verification\n",
      " 5 files changed, 180 insertions(+), 7 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/michaelmurrayiv/stochastic-gradient-descent.git\n",
      "   2e7c9d4..236c519  main -> main\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "\n",
    "git add .\n",
    "git commit -m \"Debugged Adam implementation, added test case for convergence speed\"\n",
    "git push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a5vpjuemKmka"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
